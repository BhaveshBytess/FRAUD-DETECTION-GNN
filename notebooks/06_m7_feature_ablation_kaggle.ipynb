{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c31cd3d",
   "metadata": {},
   "source": [
    "# M7 — GraphSAGE Feature Ablation (Kaggle GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a59ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_auc_score, roc_curve, f1_score\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "KAGGLE_CODE = Path('/kaggle/input/elliptic-gnn-code')\n",
    "WORKDIR = Path('/kaggle/working/elliptic-gnn-baselines')\n",
    "if KAGGLE_CODE.exists():\n",
    "    if not WORKDIR.exists():\n",
    "        shutil.copytree(KAGGLE_CODE, WORKDIR, dirs_exist_ok=True)\n",
    "    os.chdir(WORKDIR)\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/kaggle/input/elliptic-fraud-data/Elliptic++ Dataset')\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_PATH = PROJECT_ROOT / 'data' / 'Elliptic++ Dataset'\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError('Elliptic++ dataset not found.')\n",
    "\n",
    "print('Loading Elliptic++ dataset...')\n",
    "features_df = pd.read_csv(DATA_PATH / 'txs_features.csv')\n",
    "classes_df = pd.read_csv(DATA_PATH / 'txs_classes.csv')\n",
    "edges_df = pd.read_csv(DATA_PATH / 'txs_edgelist.csv')\n",
    "print(f\"✓ Features: {features_df.shape}\")\n",
    "print(f\"✓ Classes: {classes_df.shape}\")\n",
    "print(f\"✓ Edges: {edges_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_FEATURES = [f\"Local_feature_{i}\" for i in range(1, 94)]\n",
    "AGGREGATE_FEATURES = [f\"Aggregate_feature_{i}\" for i in range(1, 73)]\n",
    "STRUCTURAL_FEATURES = [\n",
    "    'in_txs_degree','out_txs_degree','total_BTC','fees','size',\n",
    "    'num_input_addresses','num_output_addresses',\n",
    "    'in_BTC_min','in_BTC_max','in_BTC_mean','in_BTC_median','in_BTC_total',\n",
    "    'out_BTC_min','out_BTC_max','out_BTC_mean','out_BTC_median','out_BTC_total'\n",
    "]\n",
    "\n",
    "FEATURE_CONFIGS = [\n",
    "    ('full', None),\n",
    "    ('local_only', LOCAL_FEATURES),\n",
    "    ('aggregate_only', AGGREGATE_FEATURES),\n",
    "    ('local_plus_structural', LOCAL_FEATURES + STRUCTURAL_FEATURES)\n",
    "]\n",
    "print('Configured feature subsets:')\n",
    "for name, cols in FEATURE_CONFIGS:\n",
    "    print(f\"  - {name}: {'all' if cols is None else len(cols)} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(feature_subset):\n",
    "    data_df = features_df.merge(classes_df, on='txId', how='left')\n",
    "    data_df['class'] = data_df['class'].fillna(3).astype(int)\n",
    "\n",
    "    base_feature_cols = [c for c in data_df.columns if c not in ['txId', 'Time step', 'class']]\n",
    "    if feature_subset is None:\n",
    "        feature_cols = base_feature_cols\n",
    "    else:\n",
    "        feature_cols = [c for c in feature_subset if c in base_feature_cols]\n",
    "        if not feature_cols:\n",
    "            raise ValueError('Selected feature subset has no matching columns in dataset.')\n",
    "\n",
    "    feat_df = data_df[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    x_np = feat_df.astype(np.float32).values\n",
    "    mean = x_np.mean(axis=0)\n",
    "    std = x_np.std(axis=0)\n",
    "    std[std < 1e-6] = 1.0\n",
    "    x_np = (x_np - mean) / std\n",
    "    x = torch.from_numpy(x_np).float()\n",
    "    x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    timestamps = data_df['Time step'].values\n",
    "    y_raw = data_df['class'].values\n",
    "    y = np.where(y_raw == 1, 1, np.where(y_raw == 2, 0, -1))\n",
    "    y = torch.LongTensor(y)\n",
    "\n",
    "    tx_ids = data_df['txId'].values\n",
    "    tx_id_to_idx = {tx_id: idx for idx, tx_id in enumerate(tx_ids)}\n",
    "\n",
    "    valid_edges = edges_df[\n",
    "        edges_df['txId1'].isin(tx_id_to_idx) &\n",
    "        edges_df['txId2'].isin(tx_id_to_idx)\n",
    "    ]\n",
    "    edge_src = valid_edges['txId1'].map(tx_id_to_idx).values\n",
    "    edge_dst = valid_edges['txId2'].map(tx_id_to_idx).values\n",
    "    edge_index = torch.LongTensor(np.vstack([edge_src, edge_dst]))\n",
    "\n",
    "    num_nodes = len(data_df)\n",
    "    self_loop = torch.arange(num_nodes)\n",
    "    edge_index = torch.cat([\n",
    "        edge_index,\n",
    "        torch.stack([self_loop, self_loop], dim=0)\n",
    "    ], dim=1)\n",
    "\n",
    "    sorted_times = np.sort(np.unique(timestamps))\n",
    "    n_timesteps = len(sorted_times)\n",
    "    train_end_idx = int(n_timesteps * 0.6)\n",
    "    val_end_idx = int(n_timesteps * 0.8)\n",
    "    train_time_end = sorted_times[train_end_idx - 1]\n",
    "    val_time_end = sorted_times[val_end_idx - 1]\n",
    "\n",
    "    labeled_mask = y >= 0\n",
    "    train_mask = torch.BoolTensor((timestamps <= train_time_end) & labeled_mask.numpy())\n",
    "    val_mask = torch.BoolTensor((timestamps > train_time_end) & (timestamps <= val_time_end) & labeled_mask.numpy())\n",
    "    test_mask = torch.BoolTensor((timestamps > val_time_end) & labeled_mask.numpy())\n",
    "\n",
    "    print(f\"    Train {train_mask.sum():,} | Val {val_mask.sum():,} | Test {test_mask.sum():,}\")\n",
    "    return x, y, edge_index, train_mask, val_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a85f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=128, out_channels=2, num_layers=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        if num_layers > 1:\n",
    "            self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "        else:\n",
    "            self.convs[0] = SAGEConv(in_channels, out_channels)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return self.convs[-1](x, edge_index)\n",
    "\n",
    "\n",
    "def train_graphsage(x, y, edge_index, train_mask, val_mask):\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    edge_index = edge_index.to(DEVICE)\n",
    "    train_mask = train_mask.to(DEVICE)\n",
    "    val_mask = val_mask.to(DEVICE)\n",
    "\n",
    "    model = GraphSAGE(in_channels=x.shape[1]).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val = 0.0\n",
    "    best_state = None\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x, edge_index)\n",
    "        loss = criterion(out[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(x, edge_index)\n",
    "            val_loss = criterion(out[val_mask], y[val_mask]).item()\n",
    "            val_probs = F.softmax(out[val_mask], dim=1)[:, 1].cpu().numpy()\n",
    "            val_labels = y[val_mask].cpu().numpy()\n",
    "            val_pr = average_precision_score(val_labels, val_probs)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"    Epoch {epoch+1:03d}: loss={loss.item():.4f} | val_PR={val_pr:.4f}\")\n",
    "\n",
    "        if val_pr > best_val:\n",
    "            best_val = val_pr\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, x, y, edge_index, val_mask, test_mask):\n",
    "    model.eval()\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    edge_index = edge_index.to(DEVICE)\n",
    "    val_mask = val_mask.to(DEVICE)\n",
    "    test_mask = test_mask.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(x, edge_index)\n",
    "        val_probs = F.softmax(out[val_mask], dim=1)[:, 1].cpu().numpy()\n",
    "        val_labels = y[val_mask].cpu().numpy()\n",
    "        test_probs = F.softmax(out[test_mask], dim=1)[:, 1].cpu().numpy()\n",
    "        test_labels = y[test_mask].cpu().numpy()\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(val_labels, val_probs)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)] if len(thresholds) else 0.5\n",
    "\n",
    "    pr_auc = average_precision_score(test_labels, test_probs)\n",
    "    roc_auc = roc_auc_score(test_labels, test_probs)\n",
    "    preds = (test_probs >= best_threshold).astype(int)\n",
    "    f1 = f1_score(test_labels, preds)\n",
    "\n",
    "    def recall_at_k(y_true, scores, frac):\n",
    "        k = max(1, int(len(y_true) * frac))\n",
    "        idx = np.argsort(scores)[-k:]\n",
    "        return y_true[idx].sum() / y_true.sum()\n",
    "\n",
    "    return {\n",
    "        'pr_auc': float(pr_auc),\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'f1': float(f1),\n",
    "        'threshold': float(best_threshold),\n",
    "        'recall@0.5%': float(recall_at_k(test_labels, test_probs, 0.005)),\n",
    "        'recall@1.0%': float(recall_at_k(test_labels, test_probs, 0.01)),\n",
    "        'recall@2.0%': float(recall_at_k(test_labels, test_probs, 0.02))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59844d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
    "PLOTS_DIR = REPORTS_DIR / 'plots'\n",
    "CHECKPOINT_DIR = PROJECT_ROOT / 'checkpoints'\n",
    "for path in (REPORTS_DIR, PLOTS_DIR, CHECKPOINT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for config_name, feature_cols in FEATURE_CONFIGS:\n",
    "    print('\\n' + '='*80)\n",
    "    print(f\"Running GraphSAGE for config: {config_name}\")\n",
    "    print('='*80)\n",
    "\n",
    "    x, y, edge_index, train_mask, val_mask, test_mask = prepare_data(feature_cols)\n",
    "    model = train_graphsage(x, y, edge_index, train_mask, val_mask)\n",
    "    metrics = evaluate_model(model, x, y, edge_index, val_mask, test_mask)\n",
    "\n",
    "    prefix = f\"graphsage_{config_name}\"\n",
    "    metrics_path = REPORTS_DIR / f\"{prefix}_metrics.json\"\n",
    "    checkpoint_path = CHECKPOINT_DIR / f\"{prefix}_best.pt\"\n",
    "\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    print(f\"    Saved {metrics_path.name}, {checkpoint_path.name}\")\n",
    "    print(f\"    PR-AUC={metrics['pr_auc']:.4f} | ROC-AUC={metrics['roc_auc']:.4f} | F1={metrics['f1']:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'feature_count': x.shape[1],\n",
    "        **metrics,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = REPORTS_DIR / 'm7_graphsage_ablation_summary.csv'\n",
    "results_df.to_csv(summary_path, index=False)\n",
    "print(f\"Summary CSV saved to {summary_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
