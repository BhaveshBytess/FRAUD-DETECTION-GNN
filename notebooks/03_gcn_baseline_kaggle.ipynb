{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Fraud Detection - Kaggle GPU Training\n",
    "\n",
    "This notebook trains a GCN model on the Elliptic++ dataset for Bitcoin fraud detection.\n",
    "\n",
    "**Requirements:**\n",
    "- GPU enabled (Settings → Accelerator → GPU T4 x2)\n",
    "- Elliptic dataset linked (Add Data → elliptic-fraud-detection)\n",
    "\n",
    "**Expected Runtime:** ~10-15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-geometric -q\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"✓ Seed set to 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path (adjust if needed)\n",
    "DATA_PATH = '/kaggle/input/elliptic-fraud-detection/'\n",
    "\n",
    "print(\"Loading Elliptic++ dataset...\")\n",
    "\n",
    "# Load CSVs\n",
    "features_df = pd.read_csv(DATA_PATH + 'txs_features.csv')\n",
    "classes_df = pd.read_csv(DATA_PATH + 'txs_classes.csv')\n",
    "edges_df = pd.read_csv(DATA_PATH + 'txs_edgelist.csv')\n",
    "\n",
    "print(f\"✓ Features: {features_df.shape}\")\n",
    "print(f\"✓ Classes: {classes_df.shape}\")\n",
    "print(f\"✓ Edges: {edges_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features and classes\n",
    "data_df = features_df.merge(classes_df, on='txId', how='left')\n",
    "data_df['class'] = data_df['class'].fillna(3).astype(int)\n",
    "\n",
    "print(f\"Total transactions: {len(data_df):,}\")\n",
    "print(f\"Fraud (class=1): {(data_df['class'] == 1).sum():,}\")\n",
    "print(f\"Legitimate (class=2): {(data_df['class'] == 2).sum():,}\")\n",
    "print(f\"Unlabeled (class=3): {(data_df['class'] == 3).sum():,}\")\n",
    "\n",
    "# Extract features\n",
    "feature_cols = [col for col in data_df.columns if col not in ['txId', 'Time step', 'class']]\n",
    "x = torch.FloatTensor(data_df[feature_cols].values)\n",
    "\n",
    "# Normalize features\n",
    "x = (x - x.mean(dim=0)) / (x.std(dim=0) + 1e-8)\n",
    "\n",
    "# Extract timestamps\n",
    "timestamps = data_df['Time step'].values\n",
    "\n",
    "# Convert labels: 1=fraud→1, 2=legit→0, 3=unlabeled→-1\n",
    "y_raw = data_df['class'].values\n",
    "y = np.where(y_raw == 1, 1, np.where(y_raw == 2, 0, -1))\n",
    "y = torch.LongTensor(y)\n",
    "\n",
    "print(f\"\\n✓ Features shape: {x.shape}\")\n",
    "print(f\"✓ Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tx_id to index mapping\n",
    "tx_ids = data_df['txId'].values\n",
    "tx_id_to_idx = {tx_id: idx for idx, tx_id in enumerate(tx_ids)}\n",
    "\n",
    "# Build edge index\n",
    "valid_edges = edges_df[\n",
    "    edges_df['txId1'].isin(tx_id_to_idx) & \n",
    "    edges_df['txId2'].isin(tx_id_to_idx)\n",
    "]\n",
    "\n",
    "edge_src = valid_edges['txId1'].map(tx_id_to_idx).values\n",
    "edge_dst = valid_edges['txId2'].map(tx_id_to_idx).values\n",
    "edge_index = torch.LongTensor(np.vstack([edge_src, edge_dst]))\n",
    "\n",
    "print(f\"✓ Edge index shape: {edge_index.shape}\")\n",
    "print(f\"✓ Total edges: {edge_index.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Temporal Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal split (60/20/20)\n",
    "sorted_times = np.sort(np.unique(timestamps))\n",
    "n_timesteps = len(sorted_times)\n",
    "\n",
    "train_end_idx = int(n_timesteps * 0.6)\n",
    "val_end_idx = int(n_timesteps * 0.8)\n",
    "\n",
    "train_time_end = sorted_times[train_end_idx - 1]\n",
    "val_time_end = sorted_times[val_end_idx - 1]\n",
    "\n",
    "# Create masks\n",
    "labeled_mask = y >= 0\n",
    "train_mask = torch.BoolTensor((timestamps <= train_time_end) & labeled_mask.numpy())\n",
    "val_mask = torch.BoolTensor((timestamps > train_time_end) & (timestamps <= val_time_end) & labeled_mask.numpy())\n",
    "test_mask = torch.BoolTensor((timestamps > val_time_end) & labeled_mask.numpy())\n",
    "\n",
    "print(f\"Train: {train_mask.sum():,} nodes (time <= {train_time_end})\")\n",
    "print(f\"Val:   {val_mask.sum():,} nodes (time <= {val_time_end})\")\n",
    "print(f\"Test:  {test_mask.sum():,} nodes\")\n",
    "\n",
    "# Class balance\n",
    "train_fraud = (y[train_mask] == 1).sum().item()\n",
    "val_fraud = (y[val_mask] == 1).sum().item()\n",
    "test_fraud = (y[test_mask] == 1).sum().item()\n",
    "\n",
    "print(f\"\\nTrain: {train_fraud:,} fraud ({100*train_fraud/train_mask.sum():.2f}%)\")\n",
    "print(f\"Val:   {val_fraud:,} fraud ({100*val_fraud/val_mask.sum():.2f}%)\")\n",
    "print(f\"Test:  {test_fraud:,} fraud ({100*test_fraud/test_mask.sum():.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=128, out_channels=2, num_layers=2, dropout=0.4):\n",
    "        super(GCN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        if num_layers > 1:\n",
    "            self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "        else:\n",
    "            self.convs[0] = GCNConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = GCN(in_channels=x.shape[1], hidden_channels=128, out_channels=2, num_layers=2, dropout=0.4)\n",
    "model = model.to(device)\n",
    "\n",
    "# Move data to device\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "val_mask = val_mask.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "\n",
    "print(f\"✓ Model on device: {device}\")\n",
    "print(f\"✓ Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_pr_auc = 0\n",
    "best_epoch = 0\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_pr_auc': []}\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Train\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x, edge_index)\n",
    "    loss = criterion(out[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(x, edge_index)\n",
    "        val_loss = criterion(out[val_mask], y[val_mask]).item()\n",
    "        val_probs = F.softmax(out[val_mask], dim=1)[:, 1].cpu().numpy()\n",
    "        val_labels = y[val_mask].cpu().numpy()\n",
    "        val_pr_auc = average_precision_score(val_labels, val_probs)\n",
    "    \n",
    "    history['train_loss'].append(loss.item())\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_pr_auc'].append(val_pr_auc)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:03d}: Train Loss={loss.item():.4f}, Val Loss={val_loss:.4f}, Val PR-AUC={val_pr_auc:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_pr_auc > best_val_pr_auc:\n",
    "        best_val_pr_auc = val_pr_auc\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0\n",
    "        best_state = model.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        print(f\"Best Val PR-AUC: {best_val_pr_auc:.4f} at epoch {best_epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_state)\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val', linewidth=2)\n",
    "axes[0].axvline(best_epoch, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training History')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# PR-AUC\n",
    "axes[1].plot(history['val_pr_auc'], color='green', linewidth=2)\n",
    "axes[1].axvline(best_epoch, color='r', linestyle='--', alpha=0.5)\n",
    "axes[1].axhline(best_val_pr_auc, color='g', linestyle=':', alpha=0.5)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('PR-AUC')\n",
    "axes[1].set_title('Validation PR-AUC')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gcn_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Saved: gcn_training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x, edge_index)\n",
    "    test_probs = F.softmax(out[test_mask], dim=1)[:, 1].cpu().numpy()\n",
    "    test_labels = y[test_mask].cpu().numpy()\n",
    "\n",
    "# Compute metrics\n",
    "test_pr_auc = average_precision_score(test_labels, test_probs)\n",
    "test_roc_auc = roc_auc_score(test_labels, test_probs)\n",
    "\n",
    "# Find best threshold on validation\n",
    "precision_val, recall_val, thresholds = precision_recall_curve(val_labels, val_probs)\n",
    "f1_scores = 2 * (precision_val * recall_val) / (precision_val + recall_val + 1e-8)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "test_preds = (test_probs >= best_threshold).astype(int)\n",
    "test_f1 = f1_score(test_labels, test_preds)\n",
    "\n",
    "# Recall@K\n",
    "def recall_at_k(y_true, y_score, k_frac=0.01):\n",
    "    k = max(1, int(len(y_true) * k_frac))\n",
    "    top_k_idx = np.argsort(y_score)[-k:]\n",
    "    return y_true[top_k_idx].sum() / y_true.sum()\n",
    "\n",
    "recall_05 = recall_at_k(test_labels, test_probs, 0.005)\n",
    "recall_10 = recall_at_k(test_labels, test_probs, 0.01)\n",
    "recall_20 = recall_at_k(test_labels, test_probs, 0.02)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PR-AUC:      {test_pr_auc:.4f} ⭐ (primary)\")\n",
    "print(f\"ROC-AUC:     {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score:    {test_f1:.4f}\")\n",
    "print(f\"Threshold:   {best_threshold:.4f}\")\n",
    "print(f\"\\nRecall@0.5%: {recall_05:.4f}\")\n",
    "print(f\"Recall@1.0%: {recall_10:.4f}\")\n",
    "print(f\"Recall@2.0%: {recall_20:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Plot PR and ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test, recall_test, _ = precision_recall_curve(test_labels, test_probs)\n",
    "fpr, tpr, _ = roc_curve(test_labels, test_probs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# PR Curve\n",
    "axes[0].plot(recall_test, precision_test, linewidth=2.5, label=f'GCN (PR-AUC={test_pr_auc:.4f})')\n",
    "axes[0].axhline(test_labels.mean(), color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Baseline')\n",
    "axes[0].set_xlabel('Recall', fontsize=12)\n",
    "axes[0].set_ylabel('Precision', fontsize=12)\n",
    "axes[0].set_title('Precision-Recall Curve (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# ROC Curve\n",
    "axes[1].plot(fpr, tpr, linewidth=2.5, label=f'GCN (ROC-AUC={test_roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Baseline')\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gcn_pr_roc_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Saved: gcn_pr_roc_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'pr_auc': float(test_pr_auc),\n",
    "    'roc_auc': float(test_roc_auc),\n",
    "    'f1': float(test_f1),\n",
    "    'threshold': float(best_threshold),\n",
    "    'recall@0.5%': float(recall_05),\n",
    "    'recall@1.0%': float(recall_10),\n",
    "    'recall@2.0%': float(recall_20),\n",
    "    'best_epoch': int(best_epoch + 1),\n",
    "    'best_val_pr_auc': float(best_val_pr_auc)\n",
    "}\n",
    "\n",
    "with open('gcn_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"✓ Saved: gcn_metrics.json\")\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'metrics': metrics,\n",
    "    'config': {'in_channels': x.shape[1], 'hidden_channels': 128, 'num_layers': 2}\n",
    "}, 'gcn_best.pt')\n",
    "\n",
    "print(\"✓ Saved: gcn_best.pt\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL RESULTS SAVED!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDownload these files:\")\n",
    "print(\"  - gcn_metrics.json\")\n",
    "print(\"  - gcn_training_history.png\")\n",
    "print(\"  - gcn_pr_roc_curves.png\")\n",
    "print(\"  - gcn_best.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
